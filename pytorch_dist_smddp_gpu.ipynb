{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***BONUS: PyTorch SageMaker Data Parallel Distributed Training with Amazon SageMaker***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker --upgrade -q\n",
    "# !pip install ipywidgets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import essentials packages, start a sagemaker session and specify the bucket name you created in the pre-requsites section of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_name    = sagemaker_session.default_bucket()\n",
    "jobs_folder    = 'jobs'\n",
    "dataset_folder = 'datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1000/0*GRfvsrvtfpRm400-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the training data\n",
    "The CIFAR-10 dataset is a subset of the 80 million tiny images dataset. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10('cifar10-dataset', \n",
    "                                     train=True, \n",
    "                                     download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = sagemaker_session.upload_data(path='cifar10-dataset', \n",
    "                                         key_prefix=f'{dataset_folder}/cifar10-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Specify hyperparameters, instance type and number of instances to distribute training to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name   = f'pytorch-smddp-dist-{time.strftime(\"%Y-%m-%d-%H-%M-%S-%j\", time.gmtime())}'\n",
    "output_path = f's3://{bucket_name}/{jobs_folder}'\n",
    "\n",
    "hyperparameters = {'epochs'       : 15, \n",
    "                   'lr'           : 0.01,\n",
    "                   'momentum'     : 0.9,\n",
    "                   'batch-size'   : 256,\n",
    "                   'model-type'   : 'resnet18',\n",
    "                   'backend'      : 'smddp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = { \"smdistributed\": { \n",
    "                    \"dataparallel\": { \"enabled\": True } \n",
    "                } \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "estimator = PyTorch(entry_point          = 'cifar10-distributed-smddp-gpu.py', \n",
    "                    source_dir           = 'code',\n",
    "                    output_path          = output_path + '/',\n",
    "                    code_location        = output_path,\n",
    "                    role                 = role,\n",
    "                    instance_count       = 1,\n",
    "                    instance_type        = 'ml.p4d.24xlarge', # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge',\n",
    "                    framework_version    = '1.11.0', \n",
    "                    py_version           = 'py38',\n",
    "                    distribution         = distribution,\n",
    "                    hyperparameters      = hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Specify dataset locations in Amazon S3 and then call the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 04:58:58 Starting - Starting the training job...ProfilerReport-1655787537: InProgress\n",
      "...\n",
      "2022-06-21 04:59:46 Starting - Preparing the instances for training...........................\n",
      "2022-06-21 05:04:24 Downloading - Downloading input data\n",
      "2022-06-21 05:04:24 Training - Downloading the training image........................\n",
      "2022-06-21 05:08:23 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:No exception classes found in smdistributed.dataparallel\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_pytorch_container.training:Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_pytorch_container.training:Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_pytorch_container.training:Invoking user training script.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Creating SSH daemon.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Network interface name: eth0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Host: ['algo-1']\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:instance type: ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p4d.24xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"smddp\",\n",
      "        \"batch-size\": 256,\n",
      "        \"epochs\": 15,\n",
      "        \"lr\": 0.01,\n",
      "        \"model-type\": \"resnet18\",\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"pytorch-smddp-dist-2022-06-21-04-58-57-172\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-453691756499/jobs/pytorch-smddp-dist-2022-06-21-04-58-57-172/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10-distributed-smddp-gpu\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10-distributed-smddp-gpu.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"smddp\",\"batch-size\":256,\"epochs\":15,\"lr\":0.01,\"model-type\":\"resnet18\",\"momentum\":0.9}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10-distributed-smddp-gpu.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10-distributed-smddp-gpu\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-453691756499/jobs/pytorch-smddp-dist-2022-06-21-04-58-57-172/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\"},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"smddp\",\"batch-size\":256,\"epochs\":15,\"lr\":0.01,\"model-type\":\"resnet18\",\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"pytorch-smddp-dist-2022-06-21-04-58-57-172\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-453691756499/jobs/pytorch-smddp-dist-2022-06-21-04-58-57-172/source/sourcedir.tar.gz\",\"module_name\":\"cifar10-distributed-smddp-gpu\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10-distributed-smddp-gpu.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"smddp\",\"--batch-size\",\"256\",\"--epochs\",\"15\",\"--lr\",\"0.01\",\"--model-type\",\"resnet18\",\"--momentum\",\"0.9\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=smddp\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL-TYPE=resnet18\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x FI_EFA_USE_DEVICE_RDMA=1 smddprun /opt/conda/bin/python3.8 -m mpi4py cifar10-distributed-smddp-gpu.py --backend smddp --batch-size 256 --epochs 15 --lr 0.01 --model-type resnet18 --momentum 0.9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.4.1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:SMDDP: Single node mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Bootstrap : Using eth0:10.0.210.185<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.2.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Running on P4d platform, Setting NCCL_TOPO_FILE environment variable to /usr/local/share/aws-ofi-nccl/xml/p4d-24xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO NET/OFI Selected Provider is efa\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO comm 0x557559bb0260 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO comm 0x5602675ff580 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO comm 0x558686e2d8e0 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO comm 0x558c51b0c410 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO comm 0x55b34537e1a0 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO comm 0x55bcb3a7e2e0 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO comm 0x55970e503920 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO comm 0x560b9ea05300 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Setting affinity for GPU 2 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Setting affinity for GPU 3 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Setting affinity for GPU 4 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Setting affinity for GPU 7 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Setting affinity for GPU 5 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Setting affinity for GPU 6 to ffffff00,0000ffff,ff000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Setting affinity for GPU 1 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 00 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 00 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 00 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 00 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 00 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 00 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 00 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 00 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 01 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 01 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 01 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 01 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 01 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 01 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 01 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 01 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 02 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 02 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 02 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 02 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 02 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 02 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 02 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 02 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 03 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 03 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 03 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 03 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 03 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 03 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 03 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 03 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 04 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 04 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 04 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 04 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 04 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 04 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 04 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 04 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 05 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 05 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 05 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 05 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 05 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 05 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 05 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 05 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 06 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 06 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 06 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 06 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 06 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 06 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 06 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 06 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 07 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 07 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 07 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 07 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 07 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 07 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 07 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 07 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 08 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 08 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 08 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 08 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 08 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 08 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 08 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 08 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 09 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 09 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 09 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 09 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 09 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 09 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 09 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 09 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 10 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 10 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 10 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 10 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 10 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 10 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 10 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 10 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 11 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 11 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 11 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 11 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 11 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 11 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 11 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 11 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 12 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 12 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 12 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 12 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 12 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 12 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 12 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 12 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 13 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 13 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 13 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 13 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 13 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 13 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 13 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 13 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 14 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 14 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 14 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 14 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 14 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 14 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 14 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 14 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 15 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 15 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 15 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 15 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 15 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 15 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 15 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 16 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 15 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 16 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 16 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 16 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 16 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 16 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 16 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 17 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 16 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 17 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 17 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 17 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 17 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 17 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 17 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 17 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 18 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 18 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 18 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 18 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 18 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 18 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 18 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 19 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 18 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 19 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 19 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 19 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 19 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 19 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 19 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 19 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 20 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 20 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 20 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 20 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 20 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 20 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 20 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 21 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 20 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 21 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 21 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 21 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 21 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 21 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 21 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 21 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 22 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 22 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 22 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 22 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 22 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 22 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 22 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 23 : 2[201c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 22 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 23 : 4[901c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 23 : 5[901d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 23 : 6[a01c0] -> 7[a01d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 23 : 7[a01d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 23 : 1[101d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 23 : 3[201d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Channel 23 : 0[101c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 00 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 01 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 02 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 03 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 04 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 05 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 06 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 07 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 08 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 09 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 10 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 11 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 12 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 13 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 14 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 15 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 16 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 17 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 18 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 19 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 20 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 21 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 22 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Channel 23 : 7[a01d0] -> 6[a01c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 00 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 00 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 00 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 00 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 00 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 00 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 01 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 01 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 01 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 01 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 01 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 01 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 02 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 02 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 02 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 02 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 02 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 02 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 03 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 03 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 03 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 03 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 03 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 03 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 04 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 04 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 04 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 04 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 04 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 04 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 05 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 05 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 05 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 05 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 05 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 05 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 06 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 06 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 06 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 06 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 06 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 06 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 07 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 07 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 07 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 07 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 07 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 07 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 08 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 08 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 08 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 08 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 08 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 08 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 09 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 09 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 09 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 09 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 09 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 09 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 10 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 10 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 10 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 10 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 10 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 10 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 11 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 11 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 11 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 11 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 11 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 11 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 12 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 12 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 12 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 12 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 12 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 12 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 13 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 13 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 13 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 13 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 13 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 13 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 14 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 14 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 14 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 14 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 14 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 14 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 15 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 15 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 15 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 15 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 15 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 15 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 16 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 16 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 16 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 16 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 16 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 16 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 17 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 17 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 17 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 17 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 17 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 17 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 18 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 18 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 18 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 18 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 18 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 18 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 19 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 19 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 19 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 19 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 19 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 19 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 20 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 20 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 20 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 20 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 20 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 20 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 21 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 21 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 21 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 21 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 21 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 21 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 22 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 22 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 22 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 22 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 22 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 22 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Channel 23 : 5[901d0] -> 4[901c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Channel 23 : 6[a01c0] -> 5[901d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Channel 23 : 2[201c0] -> 1[101d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Channel 23 : 4[901c0] -> 3[201d0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Channel 23 : 1[101d0] -> 0[101c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Channel 23 : 3[201d0] -> 2[201c0] via P2P/IPC/read\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO 24 coll channels, 32 p2p channels, 32 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:126:126 [6] NCCL INFO comm 0x558686f8a8f0 rank 6 nranks 8 cudaDev 6 busId a01c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:116:116 [2] NCCL INFO comm 0x557559d0d410 rank 2 nranks 8 cudaDev 2 busId 201c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:114:114 [1] NCCL INFO comm 0x560267c032d0 rank 1 nranks 8 cudaDev 1 busId 101d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:120:120 [3] NCCL INFO comm 0x55b345981ef0 rank 3 nranks 8 cudaDev 3 busId 201d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:121:121 [4] NCCL INFO comm 0x55970eb074d0 rank 4 nranks 8 cudaDev 4 busId 901c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:580 [0] NCCL INFO comm 0x558c51c69420 rank 0 nranks 8 cudaDev 0 busId 101c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:124:124 [5] NCCL INFO comm 0x55bcb3bdb490 rank 5 nranks 8 cudaDev 5 busId 901d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:127:127 [7] NCCL INFO comm 0x560b9eb62310 rank 7 nranks 8 cudaDev 7 busId a01d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes. \u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Initialized the distributed environment: 'smddp' backend on 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Get train data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Processes 6250/50000 (12%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Processes 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:580:826 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:45.760 algo-1:580 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:45.760 algo-1:116 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:45.760 algo-1:121 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:45.760 algo-1:120 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:45.760 algo-1:126 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:45.761 algo-1:124 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:45.761 algo-1:127 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:45.765 algo-1:114 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220617-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:114 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:127 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:120 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:121 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:580 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:126 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:124 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:45.921 algo-1:116 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:114 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:120 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:121 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:127 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:126 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:580 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:116 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:45.922 algo-1:124 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:127 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:114 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:120 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:126 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:580 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:121 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:116 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:124 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:121 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:121 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:580 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:116 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:120 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:580 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:116 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:124 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:120 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:124 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:127 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:126 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:127 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:114 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:126 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:45.923 algo-1:114 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.128 algo-1:116 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.128 algo-1:124 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:124 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.129 algo-1:116 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:124 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-06-21 05:08:46.130 algo-1:116 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.144 algo-1:580 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-06-21 05:08:46.145 algo-1:580 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.150 algo-1:127 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.150 algo-1:127 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.150 algo-1:127 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:127 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.151 algo-1:126 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:127 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:126 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.152 algo-1:120 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.153 algo-1:120 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-06-21 05:08:46.154 algo-1:120 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.155 algo-1:114 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.156 algo-1:114 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:114 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.157 algo-1:121 INFO hook.py:560] name:module.layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.fc.weight count_params:512000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:560] name:module.fc.bias count_params:1000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:562] Total Trainable Params: 11689512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-06-21 05:08:46.158 algo-1:121 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:root:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.684734\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.370334\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.562493\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.357694\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.637404\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.639701\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.801739\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.678363\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.801739\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.678363\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.637404\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.684734\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.370334\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.562493\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.639701\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 1 [3200/6250 (51%)] Loss: 1.357694\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7798, Accuracy: 0.43\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.215804\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.215804\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.000842\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.310648\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.405052\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.443848\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.259316\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.000842\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.310648\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.443848\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.405052\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.259316\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.263483\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.462057\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.263483\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 2 [3200/6250 (51%)] Loss: 1.462057\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.3378, Accuracy: 0.50\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.212813\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.056784\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 0.985054\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.490573\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.212813\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.056784\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 0.985054\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.490573\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.223572\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.199374\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.223572\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.199374\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.397610\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.302789\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.397610\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 3 [3200/6250 (51%)] Loss: 1.302789\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.7963, Accuracy: 0.54\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 0.937301\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.257871\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 0.937301\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.257871\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 0.979018\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.256904\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.226199\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 0.979018\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.256904\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.226199\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 0.863086\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.144072\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.248453\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 0.863086\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.144072\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 4 [3200/6250 (51%)] Loss: 1.248453\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -20.8062, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 0.944707\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.045878\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 0.648653\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.051676\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.336836\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 0.803382\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.024317\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 0.944707\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.045878\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 0.648653\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.051676\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.336836\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 0.803382\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.024317\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.055295\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 5 [3200/6250 (51%)] Loss: 1.055295\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.4648, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.878782\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.658051\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.835948\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.796225\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 1.098837\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.999956\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 1.271452\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.658051\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.878782\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.835948\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.796225\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 1.098837\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 0.999956\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 1.271452\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 6 [3200/6250 (51%)] Loss: 1.132170\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 6 [3200/6250 (51%)] Loss: 1.132170\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.6988, Accuracy: 0.62\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.750373\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.750373\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.953619\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.953619\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.865008\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.865008\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.983051\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 1.422278\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 1.422278\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.983051\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 1.081609\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 1.081609\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 1.045111\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 1.045111\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.923832\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 7 [3200/6250 (51%)] Loss: 0.923832\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.8828, Accuracy: 0.63\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.010836\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.677879\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.711706\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.010836\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.677879\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.711706\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.024747\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.040581\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.040581\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.024747\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.959474\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.653761\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.243523\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.959474\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 1.243523\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 8 [3200/6250 (51%)] Loss: 0.653761\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4003, Accuracy: 0.65\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.620387\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.722765\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.539416\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.884547\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.918065\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.722765\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.620387\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.539416\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.884547\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.918065\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 1.011098\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.689631\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 1.011098\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 0.689631\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 9 [3200/6250 (51%)] Loss: 1.007392\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 9 [3200/6250 (51%)] Loss: 1.007392\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9031, Accuracy: 0.64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.606214\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.688869\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.764018\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.688869\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.606214\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.764018\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.753444\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.709946\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 1.147701\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.753444\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.709946\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 1.147701\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.860300\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.988257\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.860300\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 10 [3200/6250 (51%)] Loss: 0.988257\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -22.1282, Accuracy: 0.67\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.597744\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.628230\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.796577\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.573752\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.857607\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.597744\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.628230\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.796577\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.857607\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.573752\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.546008\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 1.149705\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.836486\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.836486\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 1.149705\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 11 [3200/6250 (51%)] Loss: 0.546008\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.9730, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.683709\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.585623\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.539566\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.551183\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.873227\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.897134\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.585623\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.683709\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.539566\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.551183\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.873227\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.897134\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 1.203030\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.659617\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 1.203030\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 12 [3200/6250 (51%)] Loss: 0.659617\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -22.4906, Accuracy: 0.68\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.650097\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.551683\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.797483\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.923659\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.551683\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.650097\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.797483\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.923659\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.985316\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.985316\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 1.014538\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 1.014538\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.636985\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.636985\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.707150\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 13 [3200/6250 (51%)] Loss: 0.707150\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.9581, Accuracy: 0.69\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.466660\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.488619\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.488619\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.466660\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.825837\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.517789\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.865356\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.825837\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.517789\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.865356\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 1.245048\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 1.245048\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.784578\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.784578\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.695782\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 14 [3200/6250 (51%)] Loss: 0.695782\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -22.3513, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.672015\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.603542\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.517753\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.672015\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.517753\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.603542\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.867766\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.731787\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.506932\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.908018\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.867766\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.731787\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.908018\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.506932\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.601895\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Train Epoch: 15 [3200/6250 (51%)] Loss: 0.601895\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Test set: Average loss: -21.9794, Accuracy: 0.71\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Saving trained model only on rank 0\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-training-toolkit:Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-06-21 05:11:32 Uploading - Uploading generated training model\n",
      "2022-06-21 05:11:32 Completed - Training job completed\n",
      "Training seconds: 438\n",
      "Billable seconds: 438\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': datasets}, \n",
    "              job_name=job_name, \n",
    "              wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
